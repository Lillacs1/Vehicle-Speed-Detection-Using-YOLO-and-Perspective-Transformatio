{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FUzOVs04PRlx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Ivan\\\\Desktop'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\r\n",
    "os.getcwd()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVkFHXQsNLS4",
    "outputId": "6ac0ef9a-197c-4987-9c23-12ce9628e4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q supervision \"ultralytics<=8.3.40\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyzN-31lWZsT",
    "outputId": "d1288844-47b2-4cf4-e212-f70946e53981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: supervision in c:\\users\\ivan\\anaconda2\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: contourpy>=1.0.7 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (1.2.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=9.4 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (2.32.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.62.3 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from supervision) (4.66.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from requests>=2.26.0->supervision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from requests>=2.26.0->supervision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from requests>=2.26.0->supervision) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from requests>=2.26.0->supervision) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from tqdm>=4.62.3->supervision) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ivan\\anaconda2\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVoeptnCP-vS",
    "outputId": "c82fef37-aa97-4857-a36f-4ce30a9d78e8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from supervision.assets import VideoAssets, download_assets\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "VIS-3mJxQ4f_"
   },
   "outputs": [],
   "source": [
    "SOURCE_VIDEO_PATH = '/content/Chosevid.mp4'\n",
    "TARGET_VIDEO_PATH = \"vehicles-result.mp4\"\n",
    "CONFIDENCE_THRESHOLD = 0.3\n",
    "IOU_THRESHOLD = 0.5\n",
    "MODEL_NAME = \"yolov8x.pt\"\n",
    "MODEL_RESOLUTION = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "i-8eAhfERKVP"
   },
   "outputs": [],
   "source": [
    "# Source coordinates defining the trapezoidal shape on the image\n",
    "import numpy as np\n",
    "\n",
    "SOURCE = np.array([\n",
    "    [260, 150],   # Top-left (moved right)\n",
    "    [390, 150],   # Top-right (moved left)\n",
    "    [470, 270],   # Bottom-right (moved left)\n",
    "    [150, 270]    # Bottom-left (moved right)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Target coordinates for the rectangular box\n",
    "TARGET_WIDTH = 200\n",
    "TARGET_HEIGHT = 300\n",
    "TARGET = np.array([\n",
    "    [0, 0],\n",
    "    [TARGET_WIDTH - 1, 0],\n",
    "    [TARGET_WIDTH - 1, TARGET_HEIGHT - 1],\n",
    "    [0, TARGET_HEIGHT - 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Q7SY865TR4VZ"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Could not open video at /content/Chosevid.mp4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m frame_generator \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mget_video_frames_generator(source_path\u001b[38;5;241m=\u001b[39mSOURCE_VIDEO_PATH)\n\u001b[0;32m      2\u001b[0m frame_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(frame_generator)\n\u001b[1;32m----> 3\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(frame_iterator)\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\supervision\\utils\\video.py:177\u001b[0m, in \u001b[0;36mget_video_frames_generator\u001b[1;34m(source_path, stride, start, end, iterative_seek)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_video_frames_generator\u001b[39m(\n\u001b[0;32m    144\u001b[0m     source_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    145\u001b[0m     stride: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m     iterative_seek: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    149\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m    150\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m    Get a generator that yields the frames of the video.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     video, start, end \u001b[38;5;241m=\u001b[39m _validate_and_setup_video(\n\u001b[0;32m    178\u001b[0m         source_path, start, end, iterative_seek\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    180\u001b[0m     frame_position \u001b[38;5;241m=\u001b[39m start\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\supervision\\utils\\video.py:124\u001b[0m, in \u001b[0;36m_validate_and_setup_video\u001b[1;34m(source_path, start, end, iterative_seek)\u001b[0m\n\u001b[0;32m    122\u001b[0m video \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(source_path)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m video\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not open video at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m total_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(video\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_COUNT))\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m end \u001b[38;5;241m>\u001b[39m total_frames:\n",
      "\u001b[1;31mException\u001b[0m: Could not open video at /content/Chosevid.mp4"
     ]
    }
   ],
   "source": [
    "frame_generator = sv.get_video_frames_generator(source_path=SOURCE_VIDEO_PATH)\n",
    "frame_iterator = iter(frame_generator)\n",
    "frame = next(frame_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "LqaNPopbSDPQ",
    "outputId": "6528a2d0-6ddb-43c4-aeeb-393f48bf9793"
   },
   "outputs": [],
   "source": [
    "annotated_frame = frame.copy()\n",
    "annotated_frame = sv.draw_polygon(scene=annotated_frame, polygon=SOURCE, color=sv.Color.BLUE, thickness=4)\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNZu9DFGTSKa"
   },
   "outputs": [],
   "source": [
    "class ViewTransformer:\n",
    "\n",
    "    def __init__(self, source: np.ndarray, target: np.ndarray) -> None:\n",
    "        source = source.astype(np.float32)\n",
    "        target = target.astype(np.float32)\n",
    "        self.m = cv2.getPerspectiveTransform(source, target)\n",
    "\n",
    "    def transform_points(self, points: np.ndarray) -> np.ndarray:\n",
    "        if points.size == 0:\n",
    "            return points\n",
    "\n",
    "        reshaped_points = points.reshape(-1, 1, 2).astype(np.float32)\n",
    "        transformed_points = cv2.perspectiveTransform(reshaped_points, self.m)\n",
    "        return transformed_points.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6Ej0XtiTdGK"
   },
   "outputs": [],
   "source": [
    "view_transformer = ViewTransformer(source=SOURCE, target=TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iFUxrsWTjr3",
    "outputId": "f2597fea-3eb9-44e8-d0ca-1363b3035d5f"
   },
   "outputs": [],
   "source": [
    "model = YOLO(MODEL_NAME)\n",
    "\n",
    "video_info = sv.VideoInfo.from_video_path(video_path=SOURCE_VIDEO_PATH)\n",
    "frame_generator = sv.get_video_frames_generator(source_path=SOURCE_VIDEO_PATH)\n",
    "\n",
    "# tracer initiation\n",
    "byte_track = sv.ByteTrack(\n",
    "    frame_rate=video_info.fps,track_activation_threshold=CONFIDENCE_THRESHOLD\n",
    ")\n",
    "\n",
    "# annotators configuration\n",
    "thickness = sv.draw.utils.calculate_optimal_line_thickness(\n",
    "    resolution_wh=video_info.resolution_wh\n",
    ")\n",
    "text_scale = sv.calculate_optimal_text_scale(\n",
    "    resolution_wh=video_info.resolution_wh\n",
    ")\n",
    "bounding_box_annotator = sv.BoundingBoxAnnotator(\n",
    "    thickness=thickness\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    text_scale=text_scale,\n",
    "    text_thickness=thickness,\n",
    "    text_position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "trace_annotator = sv.TraceAnnotator(\n",
    "    thickness=thickness,\n",
    "    trace_length=video_info.fps * 2,\n",
    "    position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "\n",
    "polygon_zone = sv.PolygonZone(\n",
    "    polygon=SOURCE,\n",
    "    #frame_resolution_wh=video_info.resolution_wh\n",
    ")\n",
    "\n",
    "coordinates = defaultdict(lambda: deque(maxlen=video_info.fps))\n",
    "\n",
    "# open target video\n",
    "with sv.VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
    "\n",
    "    # loop over source video frame\n",
    "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
    "\n",
    "        result = model(frame, imgsz=MODEL_RESOLUTION, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "\n",
    "        # filter out detections by class and confidence\n",
    "        detections = detections[detections.confidence > CONFIDENCE_THRESHOLD]\n",
    "        detections = detections[detections.class_id != 0]\n",
    "\n",
    "        # filter out detections outside the zone\n",
    "        detections = detections[polygon_zone.trigger(detections)]\n",
    "\n",
    "        # refine detections using non-max suppression\n",
    "        detections = detections.with_nms(IOU_THRESHOLD)\n",
    "\n",
    "        # pass detection through the tracker\n",
    "        detections = byte_track.update_with_detections(detections=detections)\n",
    "\n",
    "        points = detections.get_anchors_coordinates(\n",
    "            anchor=sv.Position.BOTTOM_CENTER\n",
    "        )\n",
    "\n",
    "        # calculate the detections position inside the target RoI\n",
    "        points = view_transformer.transform_points(points=points).astype(int)\n",
    "\n",
    "        # store detections position\n",
    "        for tracker_id, [_, y] in zip(detections.tracker_id, points):\n",
    "            coordinates[tracker_id].append(y)\n",
    "\n",
    "        # format labels\n",
    "        labels = []\n",
    "\n",
    "        for tracker_id in detections.tracker_id:\n",
    "            if len(coordinates[tracker_id]) < video_info.fps / 2:\n",
    "                labels.append(f\"#{tracker_id}\")\n",
    "            else:\n",
    "                # calculate speed\n",
    "                coordinate_start = coordinates[tracker_id][-1]\n",
    "                coordinate_end = coordinates[tracker_id][0]\n",
    "                distance = abs(coordinate_start - coordinate_end)\n",
    "                time = len(coordinates[tracker_id]) / video_info.fps\n",
    "                speed = distance / time * 3.6\n",
    "                labels.append(f\"#{tracker_id} {int(speed)} km/h\")\n",
    "\n",
    "        # annotate frame\n",
    "        annotated_frame = frame.copy()\n",
    "        annotated_frame = trace_annotator.annotate(\n",
    "            scene=annotated_frame, detections=detections\n",
    "        )\n",
    "        annotated_frame = bounding_box_annotator.annotate(\n",
    "            scene=annotated_frame, detections=detections\n",
    "        )\n",
    "        annotated_frame = label_annotator.annotate(\n",
    "            scene=annotated_frame, detections=detections, labels=labels\n",
    "        )\n",
    "\n",
    "        # add frame to target video\n",
    "        sink.write_frame(annotated_frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
